---
title: "Hard hard user interfaces."
date: 2023-09-14
draft: false
slug: "hard-hard-user-interfaces"
---

Started as someone doing ActionScript in Macromedia Flash I got into Human-Computer-Interaction after watching Jeff's Hann's multi-touch work. That's the power of a really cool demo that inspired the birth of NUIGroup community which spawned 1000s of makers all around the world making their own projector camera multitouch systems. All of it became mainstream once Apple released the iPhone to the world, and also gave birth to my interest in human-centered engineering.

## The graveyard of interaction modalities

I spent some 10 years after that playing with sensors, haptics, and gestural interfaces through multiple input modalities but nothing stuck as much as multi-touch did. Thanks to Apple's execution. Everyone's phone/tablet interaction is default multitouch. (unless you have a visual impairment).

The modalities that came and went:

1. **Multi-touch** -- Primsense evolved into Kinect, then came Wiimote, Leap but nothing stuck.
2. **Speech** -- it was Amazon's Alexa. Latest [news](https://arstechnica.com/gadgets/2022/11/amazon-alexa-is-a-colossal-failure-on-pace-to-lose-10-billion-this-year/) that its going to lose Amazon 10B.
3. **Gestural / spatial** -- the Gestalt UI [demo](https://www.youtube.com/watch?v=fe0fHTHEL9w) at the Media Lab showcased a great way to manipulate data and information in a large 3D space. The company spun off as [Oblong industries](https://www.oblong.com/).

## We return to buttons

Like I am writing this post through my keyboard and mouse, As my previous boss and mentor [Srig](https://engineering.buffalo.edu/computer-science-engineering/information-for-students/graduate-program/cse-graduate-academic-policies/it-policies/cse-ethical-use-of-computers-policy.host.html/content/shared/engineering/computer-science-engineering/profiles/departmental-advisory-board/madhvanath-sriganesh.detail.html) says people are 'effort optimizers' we eventually return back to buttons. Unless it's a very cleverly designed UX where other inputs do not shine. Examples of these are:

1. Amazon Firestick's voice input button while watching TV. Where you push to talk and input the movie name. Its annoying for other languages but I still use it.
2. Hands-free interfaces when the user is busy- like speech interaction while driving a car. Or when the doctor/Medical Scribe is taking a lot of notes.

## Solutions looking for a problem

I personally feel drawn towards these future inventive interaction demos, but as progress in my personal product and startup journey- I now feel slightly scared 'solutions looking for a problem' approach. That's one trap I used to find myself during my early inventive years where we would 'imagine' interactions that are cool and just prototype them. Maybe it's the business person inside of me now that's apprehensive of my own past approach.
