<!DOCTYPE html>
<html lang="en-us">
  <head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="robots" content="index, follow">
  <title>Testo â€” Anirudh Sharma's Blog</title>
  <meta name="description" content="Thoughts on invention, design, and technology">
  <meta property="og:site_name" content="Anirudh Sharma">
  <meta property="og:title" content="Testo">
  
  <meta property="og:type" content="article">
  <link rel="canonical" href="http://localhost:8000/blog/testo/">
  <link rel="alternate" type="application/rss+xml" title="RSS" href="http://localhost:8000/blog/index.xml">
  <link rel="stylesheet" href="http://localhost:8000/blog/css/style.css">
  
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css">
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body, {delimiters: [{left: '$$', right: '$$', display: true},{left: '$', right: '$', display: false}]});">
  </script>
</head>

  <body>
    <a href="https://anirudh.me" class="site-link">&larr; Main Site</a>

<header class="site-header">
  <a href="http://localhost:8000/blog/" class="logo">Anirudh Sharma's Blog</a>
  <nav class="nav">
    <a href="http://localhost:8000/blog/archives/">Archives</a>
    
  </nav>
</header>

    
<div class="container">
  <h1>Testo</h1>

  <div class="post-meta">
    February 13, 2026
    
    &middot; <a href="http://localhost:8000/tags/rw/">rw</a>
    
  </div>

  <div class="entry">
    <p>We will work in the CNN UI folder. But understand and we want to combine the CNN UI and the PyQT VLM RAG application.</p>
<p>Basically the whole pipeline should be like the video should be detected by the detector. Like the detector detects does the detection like it&rsquo;s working on right now and the yeah and then when the thirty second clip is recorded like thirty second clip is recorded that goes on to the PyQT, essentially everything that we want to see like what happened in that thirty second video and generate an alert.</p>
<p>So basically you&rsquo;re fusing both of the applications in a way. You take the best call on what the UI should be and I should be able to basically to detect fire and smoke and yeah I want to see what happened in the detections and the video would go with the bounding boxes to the qualified video will go to the with the bounding boxes, right? Like and the VLM storage.</p>
<span class="margin right">This is a sidenode</span>

<p>This these a test</p>
<table>
  <thead>
      <tr>
          <th>test</th>
          <th>test</th>
          <th>hey</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>hey</td>
          <td>hey</td>
          <td>hey</td>
      </tr>
  </tbody>
</table>

  </div>

  <nav class="post-nav">
    
    <a href="/blog/hard-hard-user-interfaces/">
      <div class="post-nav__label">&larr; Previous</div>
      <div class="post-nav__title">Hard hard user interfaces.</div>
    </a>
    

    
  </nav>
</div>

    <footer style="text-align:center; padding:3rem 1rem 4rem; font-family:'ET Book', Georgia, serif; font-style:italic; font-size:1rem; color:Gray;">
  &copy; 2026 Anirudh Sharma
</footer>

  </body>
</html>
